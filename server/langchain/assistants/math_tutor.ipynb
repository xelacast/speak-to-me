{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.openai_assistant import OpenAIAssistantRunnable\n",
    "from langchain_openai import ChatOpenAI\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a math tutor assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unsupported function\n\n{'type': 'code_interpreter', 'function': 'function'}\n\nFunctions must be passed in as Dict, pydantic.BaseModel, or Callable. If they're a dict they must either be in OpenAI function format or valid JSON schema with top-level 'title' and 'description' keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# OpenAIAssistantRunnable is broken until new pr is merged\u001b[39;00m\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[0;32m----> 4\u001b[0m interpreter_assistant \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIAssistantRunnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_assistant\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlangchain assistan?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a personal math tutor. Write and run code to answer math questions.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcode_interpreter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m output \u001b[38;5;241m=\u001b[39m interpreter_assistant\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms 10 - 4 raised to the 2.7\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m     12\u001b[0m output\n",
      "File \u001b[0;32m~/Developer/Projects/llms/web-llm/server/.venv/lib/python3.11/site-packages/langchain/agents/openai_assistant/base.py:213\u001b[0m, in \u001b[0;36mOpenAIAssistantRunnable.create_assistant\u001b[0;34m(cls, name, instructions, tools, model, client, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an OpenAI Assistant and instantiate the Runnable.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    OpenAIAssistantRunnable configured to run using the created assistant.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    209\u001b[0m client \u001b[38;5;241m=\u001b[39m client \u001b[38;5;129;01mor\u001b[39;00m _get_openai_client()\n\u001b[1;32m    210\u001b[0m assistant \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39massistants\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    211\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    212\u001b[0m     instructions\u001b[38;5;241m=\u001b[39minstructions,\n\u001b[0;32m--> 213\u001b[0m     tools\u001b[38;5;241m=\u001b[39m\u001b[43m[\u001b[49m\u001b[43mconvert_to_openai_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m]\u001b[49m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    215\u001b[0m     file_ids\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    216\u001b[0m )\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(assistant_id\u001b[38;5;241m=\u001b[39massistant\u001b[38;5;241m.\u001b[39mid, client\u001b[38;5;241m=\u001b[39mclient, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Developer/Projects/llms/web-llm/server/.venv/lib/python3.11/site-packages/langchain/agents/openai_assistant/base.py:213\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an OpenAI Assistant and instantiate the Runnable.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    OpenAIAssistantRunnable configured to run using the created assistant.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    209\u001b[0m client \u001b[38;5;241m=\u001b[39m client \u001b[38;5;129;01mor\u001b[39;00m _get_openai_client()\n\u001b[1;32m    210\u001b[0m assistant \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39massistants\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    211\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    212\u001b[0m     instructions\u001b[38;5;241m=\u001b[39minstructions,\n\u001b[0;32m--> 213\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[\u001b[43mconvert_to_openai_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools],  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    215\u001b[0m     file_ids\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    216\u001b[0m )\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(assistant_id\u001b[38;5;241m=\u001b[39massistant\u001b[38;5;241m.\u001b[39mid, client\u001b[38;5;241m=\u001b[39mclient, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Developer/Projects/llms/web-llm/server/.venv/lib/python3.11/site-packages/langchain_core/utils/function_calling.py:333\u001b[0m, in \u001b[0;36mconvert_to_openai_tool\u001b[0;34m(tool)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m tool\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tool:\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tool\n\u001b[0;32m--> 333\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_openai_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m: function}\n",
      "File \u001b[0;32m~/Developer/Projects/llms/web-llm/server/.venv/lib/python3.11/site-packages/langchain_core/utils/function_calling.py:308\u001b[0m, in \u001b[0;36mconvert_to_openai_function\u001b[0;34m(function)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_python_function_to_openai_function(function)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported function\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFunctions must be passed in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m as Dict, pydantic.BaseModel, or Callable. If they\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre a dict they must\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m either be in OpenAI function format or valid JSON schema with top-level\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keys.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported function\n\n{'type': 'code_interpreter', 'function': 'function'}\n\nFunctions must be passed in as Dict, pydantic.BaseModel, or Callable. If they're a dict they must either be in OpenAI function format or valid JSON schema with top-level 'title' and 'description' keys."
     ]
    }
   ],
   "source": [
    "# OpenAIAssistantRunnable is broken until new pr is merged\n",
    "\n",
    "client = OpenAI()\n",
    "interpreter_assistant = OpenAIAssistantRunnable.create_assistant(\n",
    "    name=\"langchain assistant\",\n",
    "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-4\",\n",
    "    client=client,\n",
    ")\n",
    "output = interpreter_assistant.invoke({\"content\": \"What's 10 - 4 raised to the 2.7\"})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "tools = []\n",
    "agent = OpenAIAssistantRunnable(assistant_id=\"asst_pRec50mPTEPJVrW1b1I1BIV5\", as_agent=True, tools=tools)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.agents import AgentFinish\n",
    "\n",
    "\n",
    "def execute_agent(agent, tools, input):\n",
    "    tool_map = {tool.name: tool for tool in tools}\n",
    "    response = agent.invoke(input)\n",
    "    while not isinstance(response, AgentFinish):\n",
    "        tool_outputs = []\n",
    "        for action in response:\n",
    "            tool_output = tool_map[action.tool].invoke(action.tool_input)\n",
    "            print(action.tool, action.tool_input, tool_output, end=\"\\n\\n\")\n",
    "            tool_outputs.append(\n",
    "                {\"output\": tool_output, \"tool_call_id\": action.tool_call_id}\n",
    "            )\n",
    "        response = agent.invoke(\n",
    "            {\n",
    "                \"tool_outputs\": tool_outputs,\n",
    "                \"run_id\": action.run_id,\n",
    "                \"thread_id\": action.thread_id,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai.types.beta.threads' has no attribute 'MessageContentText'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms 10 - 4 raised to the 2.7\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mreturn_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[40], line 6\u001b[0m, in \u001b[0;36mexecute_agent\u001b[0;34m(agent, tools, input)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_agent\u001b[39m(agent, tools, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m      5\u001b[0m     tool_map \u001b[38;5;241m=\u001b[39m {tool\u001b[38;5;241m.\u001b[39mname: tool \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools}\n\u001b[0;32m----> 6\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, AgentFinish):\n\u001b[1;32m      8\u001b[0m         tool_outputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Developer/Projects/llms/web-llm/server/.venv/lib/python3.11/site-packages/langchain/agents/openai_assistant/base.py:299\u001b[0m, in \u001b[0;36mOpenAIAssistantRunnable.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    298\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e, metadata\u001b[38;5;241m=\u001b[39mrun\u001b[38;5;241m.\u001b[39mdict())\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(response)\n",
      "File \u001b[0;32m~/Developer/Projects/llms/web-llm/server/.venv/lib/python3.11/site-packages/langchain/agents/openai_assistant/base.py:296\u001b[0m, in \u001b[0;36mOpenAIAssistantRunnable.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 296\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    298\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e, metadata\u001b[38;5;241m=\u001b[39mrun\u001b[38;5;241m.\u001b[39mdict())\n",
      "File \u001b[0;32m~/Developer/Projects/llms/web-llm/server/.venv/lib/python3.11/site-packages/langchain/agents/openai_assistant/base.py:490\u001b[0m, in \u001b[0;36mOpenAIAssistantRunnable._get_response\u001b[0;34m(self, run)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_messages\n\u001b[1;32m    487\u001b[0m answer: Any \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    488\u001b[0m     msg_content \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m new_messages \u001b[38;5;28;01mfor\u001b[39;00m msg_content \u001b[38;5;129;01min\u001b[39;00m msg\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    489\u001b[0m ]\n\u001b[0;32m--> 490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessageContentText\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    494\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(content\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mfor\u001b[39;00m content \u001b[38;5;129;01min\u001b[39;00m answer)\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m OpenAIAssistantFinish(\n\u001b[1;32m    496\u001b[0m     return_values\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: answer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    503\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39mrun\u001b[38;5;241m.\u001b[39mthread_id,\n\u001b[1;32m    504\u001b[0m )\n",
      "File \u001b[0;32m~/Developer/Projects/llms/web-llm/server/.venv/lib/python3.11/site-packages/langchain/agents/openai_assistant/base.py:491\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_messages\n\u001b[1;32m    487\u001b[0m answer: Any \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    488\u001b[0m     msg_content \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m new_messages \u001b[38;5;28;01mfor\u001b[39;00m msg_content \u001b[38;5;129;01min\u001b[39;00m msg\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    489\u001b[0m ]\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(content, \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessageContentText\u001b[49m)\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m content \u001b[38;5;129;01min\u001b[39;00m answer\n\u001b[1;32m    493\u001b[0m ):\n\u001b[1;32m    494\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(content\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mfor\u001b[39;00m content \u001b[38;5;129;01min\u001b[39;00m answer)\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m OpenAIAssistantFinish(\n\u001b[1;32m    496\u001b[0m     return_values\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: answer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    503\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39mrun\u001b[38;5;241m.\u001b[39mthread_id,\n\u001b[1;32m    504\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai.types.beta.threads' has no attribute 'MessageContentText'"
     ]
    }
   ],
   "source": [
    "response = execute_agent(agent, tools, {\"content\": \"What's 10 - 4 raised to the 2.7\"})\n",
    "print(response.return_values['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "from langchain.agents.openai_assistant import OpenAIAssistantRunnable\n",
    "\n",
    "\n",
    "tools = [DuckDuckGoSearchRun()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIAssistantRunnable.create_assistant(\n",
    "    name=\"langchain assistant e2b tool\",\n",
    "    instructions=\"You are a personal math tutor. Write and run code to answer math questions. You can also search the internet.\",\n",
    "    tools=tools,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    as_agent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
